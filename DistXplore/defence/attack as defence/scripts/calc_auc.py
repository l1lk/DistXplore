import argparse
import os
import numpy as np
from sklearn import metrics


def get_auc(neg_score, pos_score):
    """get the auroc resule

    Args:
        neg_score [np array]: benign samples attack costs
        pos_score [np array]: adversarial examples attack costs

    Returns:
        auc [float]: the auroc result
    """    
    pos_label = np.ones(pos_score.size, dtype=int)
    neg_label = np.zeros(neg_score.size, dtype=int)

    y_score = np.concatenate((pos_score, neg_score))
    y_label = np.concatenate((pos_label, neg_label))

    fpr, tpr, _ = metrics.roc_curve(y_label, y_score)
    auc = 1 - metrics.auc(fpr, tpr)

    return auc


def read_input_data(path):
    if not os.path.exists(path):
        raise Exception('The input data is not exist:', path)
    
    attack_costs = np.loadtxt(path, dtype=int)
    if len(attack_costs) != 1000:
        raise warnings('The input data length is not same as the raw paper, please confirm your data loading process is right.')
    return attack_costs


def main(args):
    root_path = '../results/' + args.dataset + '_attack_iter_stats'

    # load benign data
    benign_data_name = args.attack + '_attack_benign'
    benign_data_path = os.path.join(root_path, benign_data_name)
    benign_data = read_input_data(benign_data_path)

    # load adv data
    adv_list = ['fgsm', 'bim-a', 'jsma', 'cw']
    for adv in adv_list:
        adv_data_name = args.attack + '_attack_' + adv
        adv_data_path = os.path.join(root_path, adv_data_name)
        adv_data = read_input_data(adv_data_path)

        # gen the auroc results
        auc_score = get_auc(benign_data, adv_data)
        print('After use %s attack as defense, the AUROC on %s examples is: %.4f' % (args.attack, adv, auc_score))

    # * reference result
    # ||       | BIM    | BIM2   | JSMA   ||
    # || fgsm  | 0.9886 | 0.9843 | 0.9560 ||
    # || bim-a | 1.0    | 1.0    | 0.9993 ||
    # || jsma  | 0.9918 | 0.9906 | 0.9922 ||
    # || cw    | 1.0    | 1.0    | 1.0    ||
    # The above results are generated by the open source code
    # which introduces some calculation errors campared with the results in the paper
    # these errors will not have impact on our conclusions.


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '-d', '--dataset',
        help="Dataset to use; either 'mnist', 'cifar'",
        required=False, type=str, default='mnist',
    )
    parser.add_argument(
        '-a', '--attack',
        help="Attack to use, recommanded to use JSMA, BIM, BIM2 or DBA. ",
        required=True, type=str,
    )
    args = parser.parse_args()
    main(args)